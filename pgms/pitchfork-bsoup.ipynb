{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-agent: *\n",
      "Allow: /\n",
      "Disallow: /search/\n",
      "Disallow: /search\n",
      "\n",
      "Sitemap: https://pitchfork.com/sitemap.xml\n",
      "Sitemap: https://pitchfork.com/branded-sitemap.xml\n",
      "Sitemap: https://pitchfork.com/feed/google-latest-news/sitemap-google-news\n",
      "Sitemap: https://pitchfork.com/feed/sitemap\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.pitchfork.com/robots.txt'\n",
    "response  = requests.get(url)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "test = requests.get(\"https://pitchfork.com/reviews/albums/?page=2\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mozilla/5.0 (Windows NT 5.1; rv:31.0) Gecko/20100101 Firefox/31.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "## allows us to use reg expressions to search fields\n",
    "import re\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "chromedriver = \"/Applications/chromedriver\" # path to the chromedriver executable\n",
    "os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "\n",
    "# user agent\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "options = Options()\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "print(userAgent)\n",
    "options.add_argument(f'user-agent={userAgent}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Selenium to scrape album contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Dec  3 20:13:09 2017\n",
    "@author: Evan\n",
    "\"\"\"\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# driver = webdriver.Chrome(chromedriver,chrome_options=options)\n",
    "\n",
    "# #_url = \"https://www.discogs.com/sell/list?sort=price%2Cdesc&limit=100&year1=1900&year2=1970&format=Vinyl&price=over40&genre=Jazz&currency=USD&style=Hard+Bop&page=\"\n",
    "# # not just bebop\n",
    "# _url = \"https://pitchfork.com/reviews/albums/?genre=jazz/\"\n",
    "# url= _url + str(pagestart) \n",
    "\n",
    "# # starting url\n",
    "# driver.get(url)\n",
    "\n",
    "\n",
    "'''\n",
    "This function parses the HTML of the page and attempts to gather attributes like\n",
    "artist name, album, genre, date, and the review text itself, instead inputting a\n",
    "null value if the requested element is not found on the page. All of the data are\n",
    "put into a Pandas dataframe and returned for use in the gather function.\n",
    "VARIABLES\n",
    "album_link - A string that refers to the album section of a link to a Pitchfork \n",
    "review.\n",
    "e.g. '/reviews/albums/neil-young-promise-of-the-real-visitor/'\n",
    "'''\n",
    "def gather_info(album_link):\n",
    "    #page = requests.get(\"https://pitchfork.com\" + album_link) #request URL\n",
    "    page = requests.get(\"https://pitchfork.com\" + album_link) #request URL\n",
    "    soup = BeautifulSoup(page.content, 'html.parser') #parse with beautifulsoup\n",
    "    title = str(soup.find('title').string) #album and artist \n",
    "    try:\n",
    "        score = float((soup.find(class_=\"score\").string)) #score\n",
    "    except AttributeError:\n",
    "        score = None\n",
    "    try:\n",
    "        genre = soup.find(class_=\"genre-list__link\").string #genre\n",
    "    except AttributeError:\n",
    "        genre = None\n",
    "    sents = [element.text for element in soup.find_all('p')] #cleaned text output\n",
    "    string = \" \".join(sents)\n",
    " \n",
    "    # test\n",
    "    try:\n",
    "        othercat= [div.text for div in soup.find_all('a')]\n",
    "        #print(othercat)\n",
    "    except AttributeError:\n",
    "        othercat=None\n",
    " \n",
    "    # get img\n",
    "    #img1=soup.find('img')\n",
    "    try:\n",
    "        img= [item['src'] for item in soup.find_all('img')]\n",
    "        #print('bam', img)\n",
    "    except AttributeError:\n",
    "        img = None\n",
    "    \n",
    "    # get audio\n",
    "    \n",
    "    try:    \n",
    "        \n",
    "        #audio = soup.find(class_=\"multi-link\").string #genre\n",
    "        #audio= [item['href'] for item in soup.find_all('multi-link')]\n",
    "        \n",
    "#         for li in soup.find_all(class_=\"multi-link\"):\n",
    "#             audio.append(li.get('href'))\n",
    "    except AttributeError:\n",
    "        audio= None\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        date = str(soup.find(class_=\"pub-date\").string) #date\n",
    "    except AttributeError:\n",
    "        date = None\n",
    "    #create dataframe with column labels\n",
    "    d = {'artist': [get_artist(title)], 'album': [get_album(title)], 'score': [score], 'genre': [genre], 'review': [string], 'othercat':[othercat], 'img':[img], 'audio':[audio], 'best': [1 if \"Best new\" in string else 0], 'date': [date]}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function starts at Pitchfork's album reviews page and searches through a\n",
    "requested number of pages from a given start page, adding each album link to the\n",
    "queue to be scraped by the gather_info function and returning them in a list.\n",
    "VARIABLES\n",
    "pages, startPage - Integers that refer to the number of pages to scrape and the\n",
    "page to start on, respectively, while scraping through Pitchfork's album reviews\n",
    "page.\n",
    ". \n",
    "'''\n",
    "def gather_links(pages, startPage):\n",
    "    pageList = [] #list of album review pages\n",
    "    linkList = [] #list of album links\n",
    "    \n",
    "    for x in range(startPage,(startPage+pages)): #check the first n pages after the requested one\n",
    "        \n",
    "        pageList.append(requests.get(\"https://pitchfork.com/reviews/albums/?genre=jazz&page=\" + str(x))) #add each page to list\n",
    "        #pageList.append(requests.get(\"https://pitchfork.com/reviews/albums/?page=\" + str(x))) #add each page to list\n",
    "        #print('x',x,'pagelist',pageList)\n",
    "    for page in pageList:\n",
    "        print('page',page)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser') #parse its contents\n",
    "        #print(soup)\n",
    "        links = soup.find_all(class_=\"review__link\") #gather its links (in raw html)\n",
    "        #print('links',links)\n",
    "        for link in links: #for each link\n",
    "            linkList.append(link.get('href')) #append only the link itself\n",
    "        \n",
    "    return linkList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function retreives the artist name from the scraped title string.\n",
    "VARIABLES\n",
    "title - A string of a cleaned Pitchfork album review title.\n",
    "'''\n",
    "def get_artist(title):\n",
    "    str = ''\n",
    "    for character in title: #for each character in title\n",
    "        #add to string up until ':' \n",
    "        #if character is not ':':\n",
    "        if character != ':':\n",
    "            str += character\n",
    "        else:\n",
    "            break\n",
    "    return str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function retreives the album name from the scraped title string.\n",
    "VARIABLES\n",
    "title - A string of a cleaned Pitchfork album review title.\n",
    "'''          \n",
    "def get_album(title):\n",
    "    str = ''\n",
    "    #find ':' and index and start there\n",
    "    index = title.find(\":\")\n",
    "    title = title[index+2:]\n",
    "    #for each character afterwards, add it until '|'\n",
    "    for character in title:\n",
    "        #if character is '|':\n",
    "        if character == '|':\n",
    "            break\n",
    "        else:\n",
    "            str +=character\n",
    "    return str[:-14] #return just the title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function uses the other two to gather the requested number of pages starting\n",
    "from a given page, then adding them all into a single Pandas dataframe, which\n",
    "is then exported to a CSV file in the given location of the user's desktop.\n",
    "VARIABLES\n",
    "pages, startPages - Integers that refer to the number of pages to scrape and the\n",
    "page to start on, respectively, while scraping through Pitchfork's album reviews\n",
    "page.\n",
    "fileLocation - A string that gives a path in the user's desktop where the data\n",
    "should be saved. \n",
    "e.g. 'C:/Users/Evan/Documents'\n",
    "fileName - A string that gives the desired name of the .csv file. \n",
    "e.g. 'p4kReview'\n",
    "'''\n",
    "def gather(pages, startPage, fileLocation, fileName):\n",
    "    linkList = gather_links(pages, startPage) #gather links\n",
    "    print(linkList)\n",
    "    first = True #special variable for first scrape\n",
    "    newDF = pd.DataFrame()\n",
    "#     global data\n",
    "#     data=0\n",
    "    for link in linkList: #for each link        \n",
    "        \n",
    "        data = gather_info(link) #gather info\n",
    "        #if first, newDF becomes the initial dataframe\n",
    "        if first:\n",
    "            newDF = data\n",
    "            first = False\n",
    "        #otherwise append it\n",
    "        else:\n",
    "            newDF = newDF.append(data, ignore_index = True)\n",
    "    #when scraping complete, export to .csv \n",
    "    newDF.to_csv(path_or_buf = fileLocation + \"/\" + fileName + \".csv\")\n",
    "    #return true if gather was successful\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page <Response [200]>\n",
      "['/reviews/albums/bobby-womack-the-poet-the-poet-ii/', '/reviews/albums/wau-wau-collectif-yaral-sa-doom/', '/reviews/albums/various-artists-j-jazz-volume-3-deep-modern-jazz-from-japan/', '/reviews/albums/pino-palladino-blake-mills-notes-with-attachments/', '/reviews/albums/sam-gendel-fresh-bread/', '/reviews/albums/femi-kuti-made-kuti-legacy/', '/reviews/albums/archie-shepp-jason-moran-let-my-people-go/', '/reviews/albums/patricia-brennan-maquishti/', '/reviews/albums/baldi-gerycz-duo-after-commodore-perry-service-plaza/', '/reviews/albums/roland-haynes-second-wave/', '/reviews/albums/winston-cw-good-guess/', '/reviews/albums/jahari-massamba-unit-pardon-my-french/']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gather(1,1,'/Users/chrischan/Documents/02_Class/Metis/bootcamp/githubrepo/Metis_proj5/data','pitchfork_jazz_audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
